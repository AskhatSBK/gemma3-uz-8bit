{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_vram_usage(\n",
    "    num_params=27e9,             # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 27B –¥–ª—è Gemma 3 27B)\n",
    "    dtype_size=2,                # –†–∞–∑–º–µ—Ä —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ (2 –±–∞–π—Ç–∞ –¥–ª—è fp16/bf16, 1 –¥–ª—è 8bit)\n",
    "    optimizer_multiplier=1.0,    # –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞:\n",
    "                                 #    - ~4.0 –¥–ª—è Adam (fp32)\n",
    "                                 #    - ~2.0 –¥–ª—è 8-bit –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤ (AdamW 8bit)\n",
    "    grad_multiplier=0.5,         # –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤:\n",
    "                                 #    - 1.0 –¥–ª—è fp16/bf16\n",
    "                                 #    - ~0.5 –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ 8bit —Ç—Ä—é–∫–æ–≤\n",
    "    batch_size=16,               # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –Ω–∞ –æ–¥–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (–±–µ–∑ —É—á—ë—Ç–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è)\n",
    "    seq_len=8192,                # –î–ª–∏–Ω–∞ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (—Ç–æ–∫–µ–Ω–æ–≤)\n",
    "    hidden_size=7168,            # –†–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è (hidden size)\n",
    "    num_layers=64,               # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ—ë–≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞\n",
    "    activation_dtype_size=1,     # –†–∞–∑–º–µ—Ä —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (2 –±–∞–π—Ç–∞ –¥–ª—è fp16/bf16)\n",
    "    gradient_checkpointing=False  # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç–∏–Ω–≥ (—Å–Ω–∏–∂–∞–µ—Ç –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–π)\n",
    "):\n",
    "    # üíæ –ü–∞–º—è—Ç—å, –∑–∞–Ω–∏–º–∞–µ–º–∞—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –º–æ–¥–µ–ª–∏ (—Ç–æ–ª—å–∫–æ forward –≤–µ—Å–∞)\n",
    "    model_memory = num_params * dtype_size\n",
    "\n",
    "    # üíæ –ü–∞–º—è—Ç—å, –∑–∞–Ω–∏–º–∞–µ–º–∞—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ (–¥–ª—è backward pass)\n",
    "    grad_memory = num_params * dtype_size * grad_multiplier\n",
    "\n",
    "    # üíæ –ü–∞–º—è—Ç—å, –∑–∞–Ω–∏–º–∞–µ–º–∞—è —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, Adam —Ç—Ä–µ–±—É–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å –º–æ–º–µ–Ω—Ç –∏ variance)\n",
    "    optimizer_memory = num_params * dtype_size * optimizer_multiplier\n",
    "\n",
    "    # üíæ –ü–∞–º—è—Ç—å –Ω–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç batch, seq_len, hidden_size, num_layers)\n",
    "    act_memory = batch_size * seq_len * hidden_size * num_layers * activation_dtype_size\n",
    "\n",
    "    # –ï—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω gradient checkpointing ‚Äî –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, —É–º–µ–Ω—å—à–∞—è –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ (~65% —ç–∫–æ–Ω–æ–º–∏—è)\n",
    "    if gradient_checkpointing:\n",
    "        act_memory *= 0.35  # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 35% –ø–∞–º—è—Ç–∏ –Ω–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
    "\n",
    "    # üß† –û–±—â–∞—è –ø–∞–º—è—Ç—å (–≤ –±–∞–π—Ç–∞—Ö)\n",
    "    total_memory = model_memory + grad_memory + optimizer_memory + act_memory\n",
    "\n",
    "    # üìä –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤—Å—ë –≤ –≥–∏–≥–∞–±–∞–π—Ç—ã (GB)\n",
    "    return {\n",
    "        \"model_memory_GB\": model_memory / 1e9,\n",
    "        \"grad_memory_GB\": grad_memory / 1e9,\n",
    "        \"optimizer_memory_GB\": optimizer_memory / 1e9,\n",
    "        \"activations_memory_GB\": act_memory / 1e9,\n",
    "        \"total_GB\": total_memory / 1e9\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8599967d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activations_memory_GB': 10.522669875199998,\n",
      " 'grad_memory_GB': 13.5,\n",
      " 'model_memory_GB': 27.0,\n",
      " 'optimizer_memory_GB': 27.0,\n",
      " 'total_GB': 78.0226698752}\n"
     ]
    }
   ],
   "source": [
    "vram = estimate_vram_usage(\n",
    "    num_params=27e9,           # Gemma 3 27B\n",
    "    dtype_size=1,              # 8-bit –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å BitsAndBytes)\n",
    "    optimizer_multiplier=1.0,  # 8-bit –æ–ø—Ç–∏–º–∞–π–∑–µ—Ä (adamw_8bit)\n",
    "    grad_multiplier=0.5,       # –µ—Å–ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ 8-bit –∏–ª–∏ bf16 trick\n",
    "    batch_size=16,\n",
    "    seq_len=2048,\n",
    "    hidden_size=7168,\n",
    "    num_layers=64,\n",
    "    activation_dtype_size=2,   # fp16/bf16\n",
    "    gradient_checkpointing=True\n",
    ")\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(vram)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
